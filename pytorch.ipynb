{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1gU6cqcLxv9jwDtF-dCNhCX3oc9_MjrOA",
      "authorship_tag": "ABX9TyPIYreJCYFe1XGv1AtXN6kn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marxzhang/google-colab/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch From Scratch"
      ],
      "metadata": {
        "id": "y0a-_xgBZQdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# print(torch.__version__)\n",
        "# torch.cuda.is_available()\n",
        "# torch.version.cuda"
      ],
      "metadata": {
        "id": "iwemPDq5ZWz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1,2,3])\n",
        "t1 = t.cuda()\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "k4cGx1_qeaYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd = [[1,2,3],[4,5,6],[7,8,9]]\n",
        "print(dd)\n",
        "print(type(dd))\n",
        "dd1 = torch.tensor(dd)\n",
        "print(dd1)\n",
        "print(type(dd1))\n",
        "#reshape返回值是复制的结果\n",
        "dd2 = dd1.reshape(1,9)\n",
        "print(len(dd2))\n",
        "dd3 = dd2.reshape(9,1)\n",
        "print(len(dd3))\n",
        "print(dd3.shape)\n"
      ],
      "metadata": {
        "id": "ghbhkMTui_sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "t = torch.Tensor()\n",
        "print(type(t))\n",
        "#Tensor的三个属性\n",
        "print(t.dtype)\n",
        "print(t.device)\n",
        "print(t.layout)"
      ],
      "metadata": {
        "id": "tlRQE2nlvcoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.Tensor([1,2,3])\n",
        "t2 = torch.Tensor([1.,2.,3.])\n",
        "# 强制转换为float\n",
        "print(t1+t2)\n",
        "print(type(t1+t2))\n",
        "\n",
        "t3 = t1.cuda()\n",
        "print(t3.device)\n",
        "# 错误\n",
        "print(t1+t3)"
      ],
      "metadata": {
        "id": "i9R-6wt9xdI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.eye(2)\n",
        "b = torch.zeros(2,2)\n",
        "c = torch.ones(2,2)\n",
        "d = torch.rand(2,2)\n",
        "\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)"
      ],
      "metadata": {
        "id": "PGOWwLJ3MYSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(torch.get_default_dtype())\n",
        "\n",
        "\n",
        "data = np.array([1,2,3])\n",
        "# print(type(data))\n",
        "# 类的构造函数，使用的是torch的默认数据格式，也即dtype=torch.float32\n",
        "d1 = torch.Tensor(data)\n",
        "# 剩余三种都是tensor factory function，构造的都是dtype=torch.int64\n",
        "d2 = torch.tensor(data)\n",
        "\n",
        "\n",
        "# 前两种方式是复制，后两种是引用\n",
        "# 减少复制，可以提升效率\n",
        "# as_tensor支持的输入类型不止有nnumpy.ndarray，故应用更广泛\n",
        "d3 = torch.as_tensor(data)\n",
        "d4 = torch.from_numpy(data)\n",
        "\n",
        "data[0] = 0\n",
        "data[1] = 0\n",
        "data[2] = 0\n",
        "\n",
        "print(d1)\n",
        "print(d2)\n",
        "print(d3)\n",
        "print(d4)\n",
        "\n",
        "# print(d1.dtype)\n",
        "# print(type(d2))\n",
        "# print(d2.dtype)\n",
        "# print(type(d3))\n",
        "# print(type(d4))"
      ],
      "metadata": {
        "id": "BEJlFVKuKxkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1,2,3,4],[2,3,4,5],[3,4,5,6]],dtype=torch.float32)\n",
        "# # size是方法，shape是属性\n",
        "# print(t.size())\n",
        "# print(t.shape)\n",
        "# # number of elements\n",
        "# print(t.numel())\n",
        "\n",
        "t1 = t.reshape(1,12)\n",
        "print(t1)\n",
        "# 删除为1的维度\n",
        "t2 = t1.squeeze()\n",
        "print(t2)\n",
        "# 按照索引增加维度\n",
        "t3 = t2.unsqueeze(dim=1)\n",
        "print(t3)\n",
        "\n",
        "# 将任意维度的tensor展平成一个一维数组\n",
        "def flatten(t):\n",
        "    # -1代表让pytorch自己去寻找合适的数值\n",
        "    t = t.reshape(1,-1)\n",
        "    t = t.squeeze()\n",
        "    return t\n",
        "\n",
        "t4 = flatten(t)\n",
        "print(t4)"
      ],
      "metadata": {
        "id": "YOJShAmsTym4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.ones((4,4),dtype=torch.int64)\n",
        "t2 = t1*2\n",
        "t3 = t1*3\n",
        "# 在新的轴上堆叠tensors\n",
        "t = torch.stack((t1,t2,t3))\n",
        "# 若想应用卷积层，需要显式地将灰度图转化为彩色图，即增加色彩通道，虽然是1\n",
        "t = t.reshape(3,1,4,4)\n",
        "# print(t)\n",
        "# 一般来说，3是batchsize，1是通道数，4*4是图像的长宽像素数\n",
        "# 如果进行flatten，一般是将每个图片进行flatten，也即从通道的那个维度开始进行展平\n",
        "t = t.flatten(start_dim=1)\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "id": "FftQOS9Yyt5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#elementwise operation要求两个tensor是维度完全相同的\n",
        "#矩阵的加减乘除都是elementwise operation\n",
        "#但是numpy有广播机制，也即把一个scalar扩张成指定形状tensor的功能\n",
        "t1 = torch.tensor([[1,2],[3,4]],dtype = torch.int64)\n",
        "t2 = np.broadcast_to(2,t1.shape)\n",
        "#则以下三种效果相同\n",
        "# print(t1*2)\n",
        "# print(t1.mul(2))\n",
        "# print(t1*t2)\n",
        "\n",
        "\n",
        "t3 = torch.tensor([[1,2],[3,4]])\n",
        "t4 = torch.tensor([5,6])\n",
        "print(t3+t4)"
      ],
      "metadata": {
        "id": "-NN3ZUCt4KpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduction operation,可以减少tensor中的元素数量\n",
        "t = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32)\n",
        "t1 = t.sum()\n",
        "# print(t1)\n",
        "# print(t.numel())\n",
        "# 注意与dot点积有所区别，点积是矩阵乘法，比如两个向量的点积是一个值\n",
        "t2 = t.prod()\n",
        "# print(t2)\n",
        "t3 = t.mean()\n",
        "# print(t3)\n",
        "\n",
        "\n",
        "# 按照维度进行求和，该维度会被缩成1，比如2*3*3，按照dim=0求sum，则会得到1*3*3的矩阵，也即3*3，若按照dim=1求sum，则会得到2*1*3的矩阵，也即2*3\n",
        "# 参考：https://medium.com/analytics-vidhya/an-intuitive-understanding-on-tensor-sum-dimension-with-pytorch-d9b0b6ebbae\n",
        "T = torch.tensor([\n",
        "[1,1,1,1],\n",
        "[2,2,2,2],\n",
        "[3,3,3,3]],\n",
        "dtype=torch.int64)\n",
        "print(T.shape)\n",
        "# 等价于T[0]+T[1]+T[2]\n",
        "print(T.sum(dim=0))\n",
        "# 每个元素等价于T[n].sum()\n",
        "print(T.sum(dim=1))"
      ],
      "metadata": {
        "id": "XMOBlmi4J-E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch Project"
      ],
      "metadata": {
        "id": "E6TFzeqwnM_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "ILGoUlGTnVDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于数据的预处理，往往需要三个流程：\n",
        "\n",
        "\n",
        "1.   extract：将数据从数据集中提取出\n",
        "2.   transform：将数据转化成tensor\n",
        "3.   load：将数据转化成方便使用的形式"
      ],
      "metadata": {
        "id": "h2DoC1IBn2hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(root='/content/drive/MyDrive/DATA/FashionMNIST',train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=10)\n"
      ],
      "metadata": {
        "id": "srDg560honcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for train_set\n",
        "# torch.set_printoptions(linewidth=120)\n",
        "# print(len(train_set))\n",
        "# train_set.train_labels\n",
        "# train_set.train_labels.bincount()\n",
        "# sample = next(iter(train_set))\n",
        "# print(type(sample))\n",
        "# print(len(sample))\n",
        "# img,label = sample\n",
        "# # print(img)\n",
        "# print(label)\n",
        "# plt.imshow(img.squeeze(),cmap='gray')\n",
        "\n",
        "# for train_loader\n",
        "batch = next(iter(train_loader))\n",
        "# print(len(batch))\n",
        "img,label = batch\n",
        "print(img.shape)\n",
        "\n",
        "grid = torchvision.utils.make_grid(img,nrow=5)\n",
        "print(type(grid))\n",
        "print(grid.shape)\n",
        "plt.figure(figsize=(15,15))\n",
        "# plt.imshow输入的格式为(imagesize,imagesize,channels)，而grid及原始图像格式为(channels,imagesize,imagesize)\n",
        "plt.imshow(np.transpose(grid,(1,2,0)))\n"
      ],
      "metadata": {
        "id": "TuPOcL_dUI7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "构建神经网络通常是三个步骤：\n",
        "\n",
        "1.   拓展nn.Module类\n",
        "2.   将网络中的层定义成类\n",
        "3.   完成forward()方法"
      ],
      "metadata": {
        "id": "t_H04-ONyT-M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCojkxuCy4p_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}